text=element_text(family="Goudy Old Style"))
gg <- ggplotly(p)  #using plotly to make it interactive
gg
<<<<<<< HEAD
##================ 4.5 Lasso model  ================
## Creating matrices with regressors
# As the Lasso syntax needs a seperated data.matrix of regressors and a vector of outcomes, we split the set vertically:
RegressorMatrix_test = as.matrix(test_sample[,c("transfer.fee","positions", "transferage",
"league", "Status", "searchresults")])
RegressorMatrix_train=model.matrix(~ positions+transferage+
league+Status+searchresults, train_sample)
model.matrix(train_sample)
RegressorMatrix_train=model.matrix(~ transfer.fee+transferage+
league+Status+searchresults, train_sample)
M3_Lasso = glmnet(x = RegressorMatrix_train, y = train_sample$transfer.fee)
library(glmnet)
M3_Lasso = glmnet(x = RegressorMatrix_train, y = train_sample$transfer.fee)
RegressorMatrix_test=model.matrix(~ positions+transferage+
league+Status+searchresults, test_sample)
RegressorMatrix_test=model.matrix(~ positions+transferage+
league+Status+searchresults, test_sample)
M3_Lasso = glmnet(x = RegressorMatrix_train, y = train_sample$transfer.fee)
estimate_M3 = predict(M3_Lasso, RegressorMatrix_test)
View(RegressorMatrix_test)
View(RegressorMatrix_train)
train_sample.1<- train_sample %>%
select(name,transfer.fee,Status,club.to)
library(dplyr)
transfer.data = read.csv("https://raw.githubusercontent.com/basgpol/SDS-group12/master/Exam_project/transferdata.tidy.csv", encoding = "UTF8", header = TRUE)
set.seed(123)
train.indicator = sample(seq_len(nrow(transfer.data)), size = train_size)
## Splitting the data frame into a train (70 pct.) and test sample (30 pct.)
train_sample = transfer.data[train.indicator, predicting.var] # selecting observations with a train indicator
predicting.var = c("transfer.fee", "positions", #"nationality",
train_sample = transfer.data[train.indicator, predicting.var] # selecting observations with a train indicator
test_sample = transfer.data[-train.indicator, predicting.var] # selecting observations without a train indicator
transfer.data = read.csv("https://raw.githubusercontent.com/basgpol/SDS-group12/master/Exam_project/transferdata.tidy.csv", encoding = "UTF8", header = TRUE)
## creating a vector with selected predictors for transferfee ()
predicting.var = c("transfer.fee", "positions", #"nationality",
"appearances", "total.goals", "total.assists",
"minutes.pr.goal", "total.minutes.played", "contract.left.month", "transferage",
"league", "Status", "searchresults")
##================ 4.1 Dividing into a train and test sample  ================
## Creating a vector with the count of 70 pct. of the sample size
train_size = floor(0.70 * nrow(transfer.data)) # creates a vector
## setting seed to inable reproductivity
set.seed(123)
## creating a vector with random numbers (count = tran_size)
train.indicator = sample(seq_len(nrow(transfer.data)), size = train_size)
## Splitting the data frame into a train (70 pct.) and test sample (30 pct.)
train_sample = transfer.data[train.indicator, predicting.var] # selecting observations with a train indicator
test_sample = transfer.data[-train.indicator, predicting.var] # selecting observations without a train indicator
##================ 4.2 Create evaluation function  ================
RegressorMatrix_train=model.matrix(~ positions+transferage+
league+Status+searchresults, train_sample)
RegressorMatrix_test=model.matrix(~ positions+transferage+
league+Status+searchresults, test_sample)
M3_Lasso = glmnet(x = RegressorMatrix_train, y = train_sample$transfer.fee)
estimate_M3 = predict(M3_Lasso, RegressorMatrix_test)
get.rmse(test_sample$transfer.fee, estimate_M3)
get.rmse = function(real, estimate){
return(sqrt(mean((real - estimate)^2)))
}
get.rmse(test_sample$transfer.fee, estimate_M3)
M3-Lasso
M3_Lasso
estimate_M3
get.rmse(test_sample$transfer.fee, estimate_M3)
Model_2 = lm(train_sample$transfer.fee~ train_sample$positions+train_sample$Status+train_sample$transferage+train_sample$searchresults+train_sample$league) # generating linear model on training data
summary(Model_2)
estimate_M2 = predict(Model_2, test_sample)
estimate_M2
get.rmse(test_sample$transfer.fee, estimate_M2)
estimate_M1 = mean(train_sample$transfer.fee) #calculating estimate from model 1
get.rmse(test_sample$transfer.fee, estimate_M1) # calculating RMSE from estimate on test sample
RegressorMatrix_train=model.matrix(~ positions+transferage+
league+Status+searchresults, train_sample)
View(RegressorMatrix_test)
M3_Lasso
Model_3 = glmnet(x = RegressorMatrix_train, y = train_sample$transfer.fee)
estimate_M3 = predict(Model_3, RegressorMatrix_test)
lambda_values = Model_3$lambda
performance_Lasso = data.frame()
for (lambda in lambda_values){
performance_Lasso = rbind(performance_Lasso,
data.frame(lambda = lambda,
RMSError = rmse(predict(Model_3, RegressorMatrix_test, s = lambda),
test_sample$transfer.fee)))
}
for (lambda in lambda_values){
performance_Lasso = rbind(performance_Lasso,
data.frame(lambda = lambda,
RMSError = get.rmse(predict(Model_3, RegressorMatrix_test, s = lambda),
test_sample$transfer.fee)))
}
best.lambda = performance$lambda[performance$RMSError == min(performance$RMSError)]
best.lambda = performance_Lasso$lambda[performance_Lasso$RMSError == min(performance_Lasso$RMSError)]
coef(M3_Lasso, s = best.lambda)
rmse(predict(Model_3, RegressorMatrix_test, s=best.lambda), test_sample$transfer.fee)
get.rmse(predict(Model_3, RegressorMatrix_test, s=best.lambda), test_sample$transfer.fee)
transfer_hat_Lasso = predict(Model_3,RegressorMatrix_test, s = best.lambda)
View(transfer_hat_Lasso)
ggplot(performance_Lasso, aes(x = lambda, y = RMSError))+
geom_point() +
geom_line() +
theme_minimal()
s
best.lambda
performance_Lasso
lambda_values
estimate_M3
Model_3
coef(Model_3)
Model_3
performance_Lasso
ggplot(performance_Lasso, aes(x = lambda, y = RMSError))+
geom_point() +
geom_line() +
theme_minimal()
?rpart
??rpart
install.packages("rpart")
library("rpart")
Model_4=rpart(formula=transfer.fee~positions+transferage+
league+Status+searchresults, data=train_sample)
printcp(Model_4)
Model_4=rpart(formula=transfer.fee~positions+transferage+
league+Status+searchresults+contractleft_month, data=train_sample)
Model_4=rpart(formula=transfer.fee~positions+transferage+
league+Status+searchresults+contract.left.month, data=train_sample)
Model_4=rpart(formula=transfer.fee~positions+transferage+
league+Status+searchresults+contract.left.month+total.goal+appearances, data=train_sample)
Model_4=rpart(formula=transfer.fee~positions+transferage+
league+Status+searchresults+contract.left.month+total.goals+appearances, data=train_sample)
printcp(Model_4)
train_sample = transfer.data[train.indicator, predicting.var] # selecting observations with a train indicator
test_sample = transfer.data[-train.indicator, predicting.var] # selecting observations without a train indicator
train_size = floor(0.70 * nrow(transfer.data)) # creates a vector
## setting seed to inable reproductivity
set.seed(123)
## creating a vector with random numbers (count = tran_size)
train.indicator = sample(seq_len(nrow(transfer.data)), size = train_size)
## Splitting the data frame into a train (70 pct.) and test sample (30 pct.)
train_sample = transfer.data[train.indicator, predicting.var] # selecting observations with a train indicator
test_sample = transfer.data[-train.indicator, predicting.var] # selecting observations without a train indicator
library("glmnet")
library(caret)
library(plotly)
library(ggplot2)
library(glmnet)
library(dplyr)
library(plotly)
transfer.data = read.csv("https://raw.githubusercontent.com/basgpol/SDS-group12/master/Exam_project/transferdata.final.csv", encoding = "UTF8", header = TRUE)
## creating a vector with selected predictors for transferfee ()
predicting.var = c("transfer.fee", "positions", "appearances", "total.goals", "total.assists",
"total.minutes.played", "contract.left.month","transferage",
"league", "Status", "searchresults","transferage_sq")
## Removing observations where contract lenght is unknown
transfer.data=filter(transfer.data , is.na(contract.left.month) == FALSE)
train_size = floor(0.70 * nrow(transfer.data)) # creates a vector
## setting seed to enable reproductivity
set.seed(123)
## creating a vector with random numbers (count = tran_size)
train.indicator = sample(seq_len(nrow(transfer.data)), size = train_size)
## Splitting the data frame into a train (70 pct.) and test sample (30 pct.)
train_sample = transfer.data[train.indicator,predicting.var] # selecting observations with a train indicator
test_sample = transfer.data[-train.indicator, predicting.var] # selecting observations without a train indicator
get.rmse = function(real, estimate){
return(sqrt(mean((real - estimate)^2)))
}
View(transfer.data)
transfer.data$transferage_sq = transfer.data$transferage^2
et.seed(123)
## creating a vector with random numbers (count = tran_size)
train.indicator = sample(seq_len(nrow(transfer.data)), size = train_size)
## Splitting the data frame into a train (70 pct.) and test sample (30 pct.)
train_sample = transfer.data[train.indicator,predicting.var] # selecting observations with a train indicator
test_sample = transfer.data[-train.indicator, predicting.var] # selecting observations without a train indicator
# creating a function that calculate the RMSE
get.rmse = function(real, estimate){
return(sqrt(mean((real - estimate)^2)))
}
## Creating matrices with all regressors beacuse the glmnet function only works with matrices
RegressorMatrix_train=model.matrix(transfer.fee~ ., train_sample)
RegressorMatrix_test=model.matrix(transfer.fee~.,test_sample)
Model_3 = glmnet(x = RegressorMatrix_train, y = train_sample$transfer.fee)
Model_3
lambda_values = Model_3$lambda
performance_Lasso = data.frame()
for (lambda in lambda_values){
performance_Lasso = rbind(performance_Lasso,
data.frame(lambda = lambda,
RMSE = get.rmse(predict(Model_3, RegressorMatrix_test, s = lambda),
test_sample$transfer.fee)))
}
performance_Lasso
Model_3
estimate_M3 = predict(Model_3, RegressorMatrix_test)
get.rmse(test_sample$transfer.fee, estimate_M3)
coef(Model_3)
# Calculating RSME for each lambda
lambda_values = Model_3$lambda
performance_Lasso = data.frame()
for (lambda in lambda_values){
performance_Lasso = rbind(performance_Lasso,
data.frame(lambda = lambda,
RMSE = get.rmse(predict(Model_3, RegressorMatrix_test, s = lambda),
test_sample$transfer.fee)))
}
performance_Lasso
##Visualization of RSME as a function of lamda
ggplot(performance_Lasso, aes(x = lambda, y = RMSError))+
geom_point() +
geom_line() +
theme_minimal()
##Visualization of RSME as a function of lamda
ggplot(performance_Lasso, aes(x = lambda, y = RMSE))+
geom_point() +
geom_line() +
theme_minimal()
best.lambda = performance_Lasso$lambda[performance_Lasso$RMSError == min(performance_Lasso$RMSError)]
## Coefficients for best models
coef(Model_3, s = best.lambda)
best.lambda = performance_Lasso$lambda[performance_Lasso$RMSE == min(performance_Lasso$RMSError)]
best.lambda = performance_Lasso$lambda[performance_Lasso$RMSE == min(performance_Lasso$RMSError)]
best.lambda = performance_Lasso$lambda[performance_Lasso$RMSE == min(performance_Lasso$RMSE)]
coef(Model_3, s = best.lambda)
## RMSE for best model
Estimate_M3=predict(Model_3, RegressorMatrix_test, s=best.lambda)
get.rmse(Estimate_M3, test_sample$transfer.fee)
Model_2 = lm(transfer.fee ~ ., data = (train_sample)) # generating linear model on training data
summary(Model_2)
estimate_M2 = predict(Model_2, test_sample)
get.rmse(test_sample$transfer.fee, estimate_M2)
#=========================================================================================
##--------------------------------- 4. Prediction Models _---------------------------------
##=========================================================================================
#install.packages("glmnet")
library("glmnet")
## Notes ##
# Possible prediction models
#   Average
#   OlS
#   Lasso
#   Support Vector machine
#   Regression Tree
#   Random forest
### Proposed process
## Splitting the data randomly into a test and a training set
## Internal validation: Cross-validation on the training set
## External validation: Using the model on test set
## http://stats.stackexchange.com/questions/103459/how-do-i-know-which-method-of-cross-validation-is-best
##
#install.packages("caret")
library(caret)
library(plotly)
library(ggplot2)
library(glmnet)
library(dplyr)
library(plotly)
## Loading the final data set
transfer.data = read.csv("https://raw.githubusercontent.com/basgpol/SDS-group12/master/Exam_project/transferdata.final.csv", encoding = "UTF8", header = TRUE)
## Creating a new variable which is age squared
transfer.data$transferage_sq = transfer.data$transferage^2
## creating a vector with selected predictors for transferfee ()
predicting.var = c("transfer.fee", "positions", "appearances", "total.goals", "total.assists",
"total.minutes.played", "contract.left.month","transferage",
"league", "Status", "searchresults","transferage_sq")
## Removing observations where contract lenght is unknown
transfer.data=filter(transfer.data , is.na(contract.left.month) == FALSE)
##================ 4.1 Dividing into a train and test sample  ================
## Creating a vector with the count of 70 pct. of the sample size
train_size = floor(0.70 * nrow(transfer.data)) # creates a vector
## setting seed to enable reproductivity
set.seed(123)
## creating a vector with random numbers (count = tran_size)
train.indicator = sample(seq_len(nrow(transfer.data)), size = train_size)
## Splitting the data frame into a train (70 pct.) and test sample (30 pct.)
train_sample = transfer.data[train.indicator,predicting.var] # selecting observations with a train indicator
test_sample = transfer.data[-train.indicator, predicting.var] # selecting observations without a train indicator
## creating a function that calculate the RMSE
get.rmse = function(real, estimate){
return(sqrt(mean((real - estimate)^2)))
}
Model_2 = lm(transfer.fee ~ ., data = (train_sample)) # generating linear model on training data
summary(Model_2)
estimate_M2 = predict(Model_2, test_sample)
get.rmse(test_sample$transfer.fee, estimate_M2)
## Creating matrices with all regressors beacuse the glmnet function only works with matrices
RegressorMatrix_train=model.matrix(transfer.fee~ ., train_sample)
RegressorMatrix_test=model.matrix(transfer.fee~.,test_sample)
## Training Lasso
Model_3 = glmnet(x = RegressorMatrix_train, y = train_sample$transfer.fee)
coef(Model_3)
# Calculating RSME for each lambda
lambda_values = Model_3$lambda
performance_Lasso = data.frame()
for (lambda in lambda_values){
performance_Lasso = rbind(performance_Lasso,
data.frame(lambda = lambda,
RMSE = get.rmse(predict(Model_3, RegressorMatrix_test, s = lambda),
test_sample$transfer.fee)))
}
performance_Lasso
##Visualization of RSME as a function of lamda
ggplot(performance_Lasso, aes(x = lambda, y = RMSE))+
geom_point() +
geom_line() +
theme_minimal()
## Identifying lambda with the lowest RMSE
best.lambda = performance_Lasso$lambda[performance_Lasso$RMSE == min(performance_Lasso$RMSE)]
## Coefficients for best models
coef(Model_3, s = best.lambda)
## RMSE for best model
Estimate_M3=predict(Model_3, RegressorMatrix_test, s=best.lambda)
get.rmse(Estimate_M3, test_sample$transfer.fee)
Model_3 = glmnet(x = RegressorMatrix_train, y = train_sample$transfer.fee)
coef(Model_3)
Model_3
plot(Model_4,niform=TRUE,
main="Regression Tree for Transfer fee ")
text(Model_4,pretty=0,use.n=TRUE, cex=.5)
library("rpart")
library("tree")
set.seed(123)
Model_4=tree(transfer.fee~.,data=train_sample, method="anova")
Model_4$frame
plot(Model_4,niform=TRUE,
main="Regression Tree for Transfer fee ")
text(Model_4,pretty=0,use.n=TRUE, cex=.5)
set.seed(123)
Model_4=tree(transfer.fee~.,data=train_sample, method="anova")
prune.tree(Model_4) # Returns best pruned tree with 5 leaves, evaluating
# error on training data
prune.tree(Model_4,newdata=test_sample) # Ditto, but evaluates on test.set
Model_4.seq = prune.tree(Model_4) # Sequence of pruned tree sizes/errors
plot(Model_4.seq) # Plots size vs. error
Model_4.seq$dev # Vector of error rates for prunings, in order
opt.trees = which(Model_4.seq$dev == min(Model_4.seq$dev))
min(Model_4.seq$size[opt.trees]) # Size of smallest optimal tree
plot(Model_4,niform=TRUE,
main="Regression Tree for Transfer fee ")
text(Model_4,pretty=0,use.n=TRUE, cex=.5)
Tree.plot=plot(Model_4,niform=TRUE,
main="Regression Tree for Transfer fee ")
text(Model_4,pretty=0,use.n=TRUE, cex=.5)
Tree.plot
set.seed(123)
Model_4=tree(transfer.fee~.,data=train_sample, method="anova")
Model_4$frame
plot(Model_4,niform=TRUE,
main="Regression Tree for Transfer fee ")
text(Model_4,pretty=0,use.n=TRUE, cex=.5)
##Estimating transfer fee for test data
Estimate_M4=predict(Model_4,test_sample)
Estimate_M4
##Calculating RMSE
get.rmse(test_sample$transfer.fee,Estimate_M4)  #6.600
## Cross validation to find the optimal number of terminal nodes
cv.Model_4=cv.tree(Model_4)
plot(cv.Model_4$size,cv.Model_4$dev, type="b")
prune.Model_4=prune.tree(Model_4, best = 7)
predict(prune.Model_4,test_sample)
get.rmse(test_sample$transfer.fee,est)
get.rmse(test_sample$transfer.fee,"est")
get.rmse(test_sample$transfer.fee,esti)
esti=predict(prune.Model_4,test_sample)
get.rmse(test_sample$transfer.fee,esti)
library("rpart")
library("tree")
set.seed(123)
Model_4=tree(transfer.fee~.,data=train_sample, method="anova")
Model_4$frame
plot(Model_4,niform=TRUE,
main="Regression Tree for Transfer fee ")
text(Model_4,pretty=0,use.n=TRUE, cex=.5)
##Estimating transfer fee for test data
Estimate_M4=predict(Model_4,test_sample)
Estimate_M4
##Calculating RMSE
get.rmse(test_sample$transfer.fee,Estimate_M4)
cv.Model_4=cv.tree(Model_4)
plot(cv.Model_4$size,cv.Model_4$dev, type="b")
prune.Model_4=prune.tree(Model_4, best = 7)
esti=predict(prune.Model_4,test_sample)
get.rmse(test_sample$transfer.fee,esti)
set.seed(123)
Model_4=tree(transfer.fee~.,data=train_sample, method="anova")
prune.tree(Model_4) # Returns best pruned tree with 5 leaves, evaluating
# error on training data
prune.tree(Model_4,newdata=test_sample) # Ditto, but evaluates on test.set
Model_4.seq = prune.tree(Model_4) # Sequence of pruned tree sizes/errors
plot(Model_4.seq) # Plots size vs. error
Model_4.seq$dev # Vector of error rates for prunings, in order
opt.trees = which(Model_4.seq$dev == min(Model_4.seq$dev)) # Positions of
# optimal (with respect to error) trees
min(Model_4.seq$size[opt.trees]) # Size of smallest optimal tree
cv.Model_4 = cv.tree(Model_4, FUN = prune.tree)
par(mfrow = c(1, 2))
plot(cv.Model_4$size, cv.Model_4$dev, type = "b")
plot(cv.Model_4$k, cv.Model_4$dev, type = "b")
which.min(cv.Model_4$dev)
cv.Model_4[which.min(cv.Model_4$dev)]
cv.Model_4$size[which.min(cv.Model_4$dev)]
best.size=cv.Model_4$size[which.min(cv.Model_4$dev)]
prune.Model_4=prune.tree(Model_4,best = best.size)
plot(prune.Model_4)
plot(prune.Model_4);text(prune.Model_4)
pruned.predict=predict(prune.Model_4,test_sample)
pruned.estimate=predict(prune.Model_4,test_sample)
get.rmse(pruned.estimate,test_sample$transfer.fee)
library("glmnet")
## Notes ##
# Possible prediction models
#   Average
#   OlS
#   Lasso
#   Support Vector machine
#   Regression Tree
#   Random forest
### Proposed process
## Splitting the data randomly into a test and a training set
## Internal validation: Cross-validation on the training set
## External validation: Using the model on test set
## http://stats.stackexchange.com/questions/103459/how-do-i-know-which-method-of-cross-validation-is-best
##
#install.packages("caret")
library(caret)
library(plotly)
library(ggplot2)
library(glmnet)
library(dplyr)
library(plotly)
## Loading the final data set
transfer.data = read.csv("https://raw.githubusercontent.com/basgpol/SDS-group12/master/Exam_project/transferdata.final.csv", encoding = "UTF8", header = TRUE)
## Creating a new variable which is age squared
transfer.data$transferage_sq = transfer.data$transferage^2
## creating a vector with selected predictors for transferfee ()
predicting.var = c("transfer.fee", "positions", "appearances", "total.goals", "total.assists",
"total.minutes.played", "contract.left.month","transferage",
"league", "Status", "searchresults","transferage_sq")
## Removing observations where contract lenght is unknown
transfer.data=filter(transfer.data , is.na(contract.left.month) == FALSE)
##================ 4.1 Dividing into a train and test sample  ================
## Creating a vector with the count of 70 pct. of the sample size
train_size = floor(0.70 * nrow(transfer.data)) # creates a vector
## setting seed to enable reproductivity
set.seed(123)
## creating a vector with random numbers (count = tran_size)
train.indicator = sample(seq_len(nrow(transfer.data)), size = train_size)
## Splitting the data frame into a train (70 pct.) and test sample (30 pct.)
train_sample = transfer.data[train.indicator,predicting.var] # selecting observations with a train indicator
test_sample = transfer.data[-train.indicator, predicting.var] # selecting observations without a train indicator
##================ 4.2 Create evaluation function  ================
## creating a function that calculate the RMSE
get.rmse = function(real, estimate){
return(sqrt(mean((real - estimate)^2)))
}
##================ 4.3 Baseline model: Simple average from training sample  ================
estimate_M1 = mean(train_sample$transfer.fee) #calculating estimate from model 1
get.rmse(test_sample$transfer.fee, estimate_M1) # calculating RMSE from estimate on test sample
set.wd(Users/Christian/Dropbox/Universitet/SocialDataScience/SDS-group12)
setwd(Users/Christian/Dropbox/Universitet/SocialDataScience/SDS-group12)
setwd("~/Dropbox/Universitet/SocialDataScience/SDS-group12")
ibrary("glmnet")
## Notes ##
# Possible prediction models
#   Average
#   OlS
#   Lasso
#   Support Vector machine
#   Regression Tree
#   Random forest
### Proposed process
## Splitting the data randomly into a test and a training set
## Internal validation: Cross-validation on the training set
## External validation: Using the model on test set
## http://stats.stackexchange.com/questions/103459/how-do-i-know-which-method-of-cross-validation-is-best
##
#install.packages("caret")
library(caret)
library(plotly)
library(ggplot2)
library(glmnet)
library(dplyr)
library(plotly)
## Loading the final data set
transfer.data = read.csv("https://raw.githubusercontent.com/basgpol/SDS-group12/master/Exam_project/transferdata.final.csv", encoding = "UTF8", header = TRUE)
## Creating a new variable which is age squared
transfer.data$transferage_sq = transfer.data$transferage^2
## creating a vector with selected predictors for transferfee ()
predicting.var = c("transfer.fee", "positions", "appearances", "total.goals", "total.assists",
"total.minutes.played", "contract.left.month","transferage",
"league", "Status", "searchresults","transferage_sq")
## Removing observations where contract lenght is unknown
transfer.data=filter(transfer.data , is.na(contract.left.month) == FALSE)
##================ 4.1 Dividing into a train and test sample  ================
## Creating a vector with the count of 70 pct. of the sample size
train_size = floor(0.70 * nrow(transfer.data)) # creates a vector
## setting seed to enable reproductivity
set.seed(123)
## creating a vector with random numbers (count = tran_size)
train.indicator = sample(seq_len(nrow(transfer.data)), size = train_size)
## Splitting the data frame into a train (70 pct.) and test sample (30 pct.)
train_sample = transfer.data[train.indicator,predicting.var] # selecting observations with a train indicator
test_sample = transfer.data[-train.indicator, predicting.var] # selecting observations without a train indicator
##================ 4.2 Create evaluation function  ================
## creating a function that calculate the RMSE
get.rmse = function(real, estimate){
return(sqrt(mean((real - estimate)^2)))
}
View(transfer.data)
